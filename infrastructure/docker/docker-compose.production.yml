# =============================================================================
# SHIKSHA SETU - PRODUCTION DOCKER COMPOSE
# =============================================================================
# Production-grade configuration with:
# - High availability (multi-replica services)
# - Resource limits and reservations
# - Health checks with proper timeouts
# - Security hardening (read-only filesystems, security opts)
# - Proper networking isolation
# - Logging with rotation
# - Auto-restart policies
# =============================================================================

version: '3.8'

# =============================================================================
# NETWORKS - Isolated network segments
# =============================================================================
networks:
  frontend:
    driver: bridge
    driver_opts:
      com.docker.network.bridge.enable_icc: "true"
  backend:
    driver: bridge
    internal: true  # No external access, only between services
  monitoring:
    driver: bridge
    internal: true

# =============================================================================
# VOLUMES - Persistent storage with driver options
# =============================================================================
volumes:
  postgres_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${PWD}/data/postgres
  redis_data:
    driver: local
  uploads:
    driver: local
  models:
    driver: local
  prometheus_data:
    driver: local
  grafana_data:
    driver: local

# =============================================================================
# SERVICES
# =============================================================================
services:
  # ---------------------------------------------------------------------------
  # PostgreSQL Database (Primary Data Store)
  # ---------------------------------------------------------------------------
  postgres:
    image: pgvector/pgvector:pg16
    container_name: shikshasetu_postgres_prod
    restart: unless-stopped
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_INITDB_ARGS: "-E UTF8 --locale=en_US.UTF-8 --data-checksums"
      # Performance tuning
      POSTGRES_HOST_AUTH_METHOD: scram-sha-256
    command:
      - "postgres"
      - "-c"
      - "shared_buffers=512MB"
      - "-c"
      - "work_mem=64MB"
      - "-c"
      - "maintenance_work_mem=256MB"
      - "-c"
      - "effective_cache_size=1536MB"
      - "-c"
      - "random_page_cost=1.1"
      - "-c"
      - "max_connections=200"
      - "-c"
      - "log_statement=mod"
      - "-c"
      - "log_min_duration_statement=1000"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./database/init.sql:/docker-entrypoint-initdb.d/init.sql:ro
    networks:
      - backend
    ports:
      - "127.0.0.1:5432:5432"  # Bind to localhost only
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB} -q"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 2G
        reservations:
          cpus: '1.0'
          memory: 1G
    security_opt:
      - no-new-privileges:true
    logging:
      driver: "json-file"
      options:
        max-size: "20m"
        max-file: "5"
        labels: "service,environment"
    labels:
      - "com.shikshasetu.service=database"
      - "com.shikshasetu.tier=data"

  # ---------------------------------------------------------------------------
  # Redis Cache (Session + Celery Broker)
  # ---------------------------------------------------------------------------
  redis:
    image: redis:7-alpine
    container_name: shikshasetu_redis_prod
    restart: unless-stopped
    command: >
      redis-server
      --requirepass ${REDIS_PASSWORD}
      --maxmemory 512mb
      --maxmemory-policy allkeys-lru
      --appendonly yes
      --appendfsync everysec
      --tcp-keepalive 300
      --timeout 0
      --tcp-backlog 511
      --activedefrag yes
      --lazyfree-lazy-eviction yes
      --lazyfree-lazy-expire yes
    volumes:
      - redis_data:/data
    networks:
      - backend
    ports:
      - "127.0.0.1:6379:6379"  # Bind to localhost only
    healthcheck:
      test: ["CMD", "redis-cli", "-a", "${REDIS_PASSWORD}", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
    security_opt:
      - no-new-privileges:true
    read_only: true
    tmpfs:
      - /tmp:size=64M,mode=1777
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    labels:
      - "com.shikshasetu.service=cache"
      - "com.shikshasetu.tier=data"

  # ---------------------------------------------------------------------------
  # FastAPI Backend (Multiple Replicas with Load Balancing)
  # ---------------------------------------------------------------------------
  api:
    image: shikshasetu/backend:${VERSION:-latest}
    restart: unless-stopped
    env_file:
      - .env.production
    environment:
      - DATABASE_URL=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}
      - REDIS_URL=redis://:${REDIS_PASSWORD}@redis:6379/0
      - ENVIRONMENT=production
      - LOG_LEVEL=info
      - WORKERS=4
      - WORKER_CONNECTIONS=1000
      # Security
      - SECURE_COOKIES=true
      - CORS_ALLOW_CREDENTIALS=true
    volumes:
      - uploads:/app/data/uploads
      - models:/app/data/models:ro
      - ./logs/api:/app/logs
    networks:
      - frontend
      - backend
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-fsS", "--max-time", "5", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    deploy:
      replicas: 3
      resources:
        limits:
          cpus: '2.0'
          memory: 4G
        reservations:
          cpus: '1.0'
          memory: 2G
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
        window: 120s
      update_config:
        parallelism: 1
        delay: 30s
        failure_action: rollback
        order: start-first
      rollback_config:
        parallelism: 1
        delay: 10s
    security_opt:
      - no-new-privileges:true
    read_only: true
    tmpfs:
      - /tmp:size=256M,mode=1777
      - /app/data/cache:size=512M,mode=1777
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "10"
        labels: "service,environment,version"
    labels:
      - "com.shikshasetu.service=api"
      - "com.shikshasetu.tier=application"

  # ---------------------------------------------------------------------------
  # NGINX Load Balancer / Reverse Proxy
  # ---------------------------------------------------------------------------
  nginx:
    image: nginx:1.25-alpine
    container_name: shikshasetu_nginx_prod
    restart: unless-stopped
    volumes:
      - ./infrastructure/nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./infrastructure/nginx/ssl:/etc/nginx/ssl:ro
      - uploads:/usr/share/nginx/html/uploads:ro
      - ./logs/nginx:/var/log/nginx
    networks:
      - frontend
    ports:
      - "80:80"
      - "443:443"
    depends_on:
      - api
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:80/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 128M
    security_opt:
      - no-new-privileges:true
    read_only: true
    tmpfs:
      - /var/cache/nginx:size=128M
      - /var/run:size=16M
      - /tmp:size=64M
    logging:
      driver: "json-file"
      options:
        max-size: "20m"
        max-file: "5"
    labels:
      - "com.shikshasetu.service=loadbalancer"
      - "com.shikshasetu.tier=edge"

  # ---------------------------------------------------------------------------
  # Celery Worker (Background Tasks)
  # ---------------------------------------------------------------------------
  celery_worker:
    image: shikshasetu/backend:${VERSION:-latest}
    restart: unless-stopped
    command: >
      celery -A backend.tasks.celery_app worker
      --loglevel=info
      --concurrency=4
      --max-tasks-per-child=1000
      --prefetch-multiplier=4
      -Q default,high_priority,low_priority
    env_file:
      - .env.production
    environment:
      - DATABASE_URL=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}
      - REDIS_URL=redis://:${REDIS_PASSWORD}@redis:6379/0
      - CELERY_BROKER_URL=redis://:${REDIS_PASSWORD}@redis:6379/1
      - CELERY_RESULT_BACKEND=redis://:${REDIS_PASSWORD}@redis:6379/2
    volumes:
      - uploads:/app/data/uploads
      - models:/app/data/models
      - ./logs/celery:/app/logs
    networks:
      - backend
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "celery -A backend.tasks.celery_app inspect ping || exit 1"]
      interval: 60s
      timeout: 30s
      retries: 3
      start_period: 30s
    deploy:
      replicas: 2
      resources:
        limits:
          cpus: '2.0'
          memory: 4G
        reservations:
          cpus: '1.0'
          memory: 2G
    logging:
      driver: "json-file"
      options:
        max-size: "20m"
        max-file: "5"

  # Celery Beat (Scheduled Tasks)
  celery_beat:
    image: shikshasetu/backend:${VERSION:-latest}
    container_name: shikshasetu_celery_beat_prod
    restart: unless-stopped
    command: celery -A backend.tasks.celery_app beat --loglevel=info
    env_file:
      - .env.production
    environment:
      - DATABASE_URL=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}
      - REDIS_URL=redis://:${REDIS_PASSWORD}@redis:6379/0
      - CELERY_BROKER_URL=redis://:${REDIS_PASSWORD}@redis:6379/1
      - CELERY_RESULT_BACKEND=redis://:${REDIS_PASSWORD}@redis:6379/2
    networks:
      - backend
    depends_on:
      - redis
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.1'
          memory: 128M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # vLLM Model Server (GPU Required)
  vllm:
    image: vllm/vllm-openai:latest
    container_name: shikshasetu_vllm_prod
    restart: unless-stopped
    command: >
      --model ${VLLM_MODEL_NAME:-Qwen/Qwen2.5-3B-Instruct}
      --dtype float16
      --max-model-len 4096
      --gpu-memory-utilization 0.9
    environment:
      - CUDA_VISIBLE_DEVICES=0
      - VLLM_WORKER_MULTIPROC_METHOD=spawn
    volumes:
      - models:/root/.cache/huggingface
    networks:
      - backend
    ports:
      - "8001:8000"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 60s
      timeout: 30s
      retries: 3
      start_period: 300s
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
        limits:
          memory: 16G
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"

  # Frontend (React/Vite)
  frontend:
    image: shikshasetu/frontend:${VERSION:-latest}
    container_name: shikshasetu_frontend_prod
    restart: unless-stopped
    environment:
      - VITE_API_URL=https://${DOMAIN:-api.shikshasetu.in}
      - VITE_ENVIRONMENT=production
    networks:
      - frontend
    ports:
      - "3000:3000"
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:3000"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Prometheus
  prometheus:
    image: prom/prometheus:v2.47.0
    container_name: shikshasetu_prometheus_prod
    restart: unless-stopped
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=30d'
      - '--web.enable-lifecycle'
    volumes:
      - ./infrastructure/monitoring/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ./infrastructure/monitoring/prometheus-alerts.yml:/etc/prometheus/rules/alerts.yml:ro
      - prometheus_data:/prometheus
    networks:
      - monitoring
      - backend
    ports:
      - "9090:9090"
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:9090/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 1G
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Grafana
  grafana:
    image: grafana/grafana:10.1.5
    container_name: shikshasetu_grafana_prod
    restart: unless-stopped
    environment:
      - GF_SECURITY_ADMIN_USER=${GRAFANA_ADMIN_USER:-admin}
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD}
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_SERVER_ROOT_URL=https://${DOMAIN:-grafana.shikshasetu.in}
    volumes:
      - grafana_data:/var/lib/grafana
      - ./infrastructure/monitoring/grafana-dashboard.json:/etc/grafana/provisioning/dashboards/shikshasetu.json:ro
      - ./infrastructure/monitoring/grafana-datasources.yml:/etc/grafana/provisioning/datasources/prometheus.yml:ro
    networks:
      - monitoring
    ports:
      - "3001:3000"
    depends_on:
      - prometheus
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 1G
        reservations:
          cpus: '0.25'
          memory: 512M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Alertmanager
  alertmanager:
    image: prom/alertmanager:v0.26.0
    container_name: shikshasetu_alertmanager_prod
    restart: unless-stopped
    command:
      - '--config.file=/etc/alertmanager/alertmanager.yml'
      - '--storage.path=/alertmanager'
    environment:
      - SLACK_WEBHOOK_URL=${SLACK_WEBHOOK_URL}
      - PAGERDUTY_SERVICE_KEY=${PAGERDUTY_SERVICE_KEY}
    volumes:
      - ./infrastructure/monitoring/alertmanager.yml:/etc/alertmanager/alertmanager.yml:ro
    networks:
      - monitoring
    ports:
      - "9093:9093"
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:9093/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          cpus: '0.25'
          memory: 256M
        reservations:
          cpus: '0.1'
          memory: 128M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # PostgreSQL Backup (Daily)
  postgres_backup:
    image: postgres:15-alpine
    container_name: shikshasetu_backup_prod
    restart: "no"
    environment:
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_DB=${POSTGRES_DB}
      - BACKUP_DIR=/backups
    volumes:
      - ./backups:/backups
      - ./scripts/backup-postgres.sh:/backup.sh:ro
    networks:
      - backend
    depends_on:
      - postgres
    entrypoint: ["/bin/sh", "-c"]
    command:
      - |
        while true; do
          /backup.sh
          sleep 86400  # Run daily
        done
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
