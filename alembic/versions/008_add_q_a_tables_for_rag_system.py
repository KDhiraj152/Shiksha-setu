"""Add Q&A tables for RAG system

Revision ID: 008_add_q_a_tables
Revises: 007_enable_pgvector
Create Date: 2025-11-16 12:48:27.515982

"""
from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision = '008_add_q_a_tables'
down_revision = '007_enable_pgvector'
branch_labels = None
depends_on = None


def upgrade() -> None:
    # Enable pgvector extension first
    op.execute("CREATE EXTENSION IF NOT EXISTS vector")
    
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('chat_history',
    sa.Column('id', sa.UUID(), nullable=False),
    sa.Column('user_id', sa.UUID(), nullable=False),
    sa.Column('content_id', sa.UUID(), nullable=False),
    sa.Column('question', sa.Text(), nullable=False),
    sa.Column('answer', sa.Text(), nullable=False),
    sa.Column('context_chunks', sa.ARRAY(sa.UUID()), nullable=True),
    sa.Column('confidence_score', sa.Float(), nullable=True),
    sa.Column('created_at', sa.TIMESTAMP(), nullable=True),
    sa.ForeignKeyConstraint(['content_id'], ['processed_content.id'], ),
    sa.ForeignKeyConstraint(['user_id'], ['users.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_chat_history_content_id'), 'chat_history', ['content_id'], unique=False)
    op.create_index(op.f('ix_chat_history_created_at'), 'chat_history', ['created_at'], unique=False)
    op.create_index(op.f('ix_chat_history_user_id'), 'chat_history', ['user_id'], unique=False)
    op.create_table('document_chunks',
    sa.Column('id', sa.UUID(), nullable=False),
    sa.Column('content_id', sa.UUID(), nullable=False),
    sa.Column('chunk_index', sa.Integer(), nullable=False),
    sa.Column('chunk_text', sa.Text(), nullable=False),
    sa.Column('chunk_size', sa.Integer(), nullable=True),
    sa.Column('chunk_metadata', postgresql.JSONB(astext_type=sa.Text()), nullable=True),
    sa.Column('created_at', sa.TIMESTAMP(), nullable=True),
    sa.ForeignKeyConstraint(['content_id'], ['processed_content.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_document_chunks_content_id'), 'document_chunks', ['content_id'], unique=False)
    op.create_table('embeddings',
    sa.Column('id', sa.UUID(), nullable=False),
    sa.Column('chunk_id', sa.UUID(), nullable=False),
    sa.Column('content_id', sa.UUID(), nullable=False),
    sa.Column('embedding_model', sa.String(length=100), nullable=True),
    sa.Column('created_at', sa.TIMESTAMP(), nullable=True),
    sa.ForeignKeyConstraint(['chunk_id'], ['document_chunks.id'], ),
    sa.ForeignKeyConstraint(['content_id'], ['processed_content.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_embeddings_chunk_id'), 'embeddings', ['chunk_id'], unique=False)
    op.create_index(op.f('ix_embeddings_content_id'), 'embeddings', ['content_id'], unique=False)
    
    # Add vector column for embeddings (384 dimensions for sentence-transformers/all-MiniLM-L6-v2)
    op.execute("ALTER TABLE embeddings ADD COLUMN embedding vector(384)")
    
    # Drop student_profiles table (legacy)
    op.execute("DROP TABLE IF EXISTS student_profiles CASCADE")
    
    # Note: user_id columns and indexes already added in migration 004_add_user_tracking
    # Commenting out duplicate operations:
    # op.add_column('feedback', sa.Column('user_id', sa.UUID(), nullable=True))
    # op.add_column('processed_content', sa.Column('user_id', sa.UUID(), nullable=True))
    
    # Create foreign key constraints if they don't exist
    try:
        op.create_foreign_key(None, 'api_keys', 'users', ['user_id'], ['id'])
    except Exception:
        pass  # Already exists
    
    # Create indexes if they don't exist (many already created in previous migrations)
    # op.create_index(op.f('ix_feedback_content_id'), 'feedback', ['content_id'], unique=False)
    # op.create_index(op.f('ix_feedback_created_at'), 'feedback', ['created_at'], unique=False)
    # op.create_index(op.f('ix_feedback_user_id'), 'feedback', ['user_id'], unique=False)
    # op.create_index(op.f('ix_ncert_standards_grade_level'), 'ncert_standards', ['grade_level'], unique=False)
    # op.create_index(op.f('ix_ncert_standards_subject'), 'ncert_standards', ['subject'], unique=False)
    # op.create_index(op.f('ix_pipeline_logs_content_id'), 'pipeline_logs', ['content_id'], unique=False)
    # op.create_index(op.f('ix_pipeline_logs_stage'), 'pipeline_logs', ['stage'], unique=False)
    # op.create_index(op.f('ix_pipeline_logs_timestamp'), 'pipeline_logs', ['timestamp'], unique=False)
    # op.create_index(op.f('ix_processed_content_created_at'), 'processed_content', ['created_at'], unique=False)
    # op.create_index(op.f('ix_processed_content_grade_level'), 'processed_content', ['grade_level'], unique=False)
    # op.create_index(op.f('ix_processed_content_language'), 'processed_content', ['language'], unique=False)
    # op.create_index(op.f('ix_processed_content_subject'), 'processed_content', ['subject'], unique=False)
    # op.create_index(op.f('ix_processed_content_user_id'), 'processed_content', ['user_id'], unique=False)
    # ### end Alembic commands ###


def downgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index(op.f('ix_processed_content_user_id'), table_name='processed_content')
    op.drop_index(op.f('ix_processed_content_subject'), table_name='processed_content')
    op.drop_index(op.f('ix_processed_content_language'), table_name='processed_content')
    op.drop_index(op.f('ix_processed_content_grade_level'), table_name='processed_content')
    op.drop_index(op.f('ix_processed_content_created_at'), table_name='processed_content')
    op.drop_column('processed_content', 'user_id')
    op.drop_index(op.f('ix_pipeline_logs_timestamp'), table_name='pipeline_logs')
    op.drop_index(op.f('ix_pipeline_logs_stage'), table_name='pipeline_logs')
    op.drop_index(op.f('ix_pipeline_logs_content_id'), table_name='pipeline_logs')
    op.drop_index(op.f('ix_ncert_standards_subject'), table_name='ncert_standards')
    op.drop_index(op.f('ix_ncert_standards_grade_level'), table_name='ncert_standards')
    op.drop_index(op.f('ix_feedback_user_id'), table_name='feedback')
    op.drop_index(op.f('ix_feedback_created_at'), table_name='feedback')
    op.drop_index(op.f('ix_feedback_content_id'), table_name='feedback')
    op.drop_column('feedback', 'user_id')
    op.drop_constraint(None, 'api_keys', type_='foreignkey')
    op.create_table('student_profiles',
    sa.Column('id', sa.UUID(), autoincrement=False, nullable=False),
    sa.Column('language_preference', sa.VARCHAR(length=50), autoincrement=False, nullable=False),
    sa.Column('grade_level', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('subjects_of_interest', postgresql.ARRAY(sa.TEXT()), autoincrement=False, nullable=True),
    sa.Column('offline_content_cache', postgresql.JSONB(astext_type=sa.Text()), autoincrement=False, nullable=True),
    sa.Column('created_at', postgresql.TIMESTAMP(), autoincrement=False, nullable=True),
    sa.PrimaryKeyConstraint('id', name='student_profiles_pkey')
    )
    op.drop_index(op.f('ix_embeddings_content_id'), table_name='embeddings')
    op.drop_index(op.f('ix_embeddings_chunk_id'), table_name='embeddings')
    op.drop_table('embeddings')
    op.drop_index(op.f('ix_document_chunks_content_id'), table_name='document_chunks')
    op.drop_table('document_chunks')
    op.drop_index(op.f('ix_chat_history_user_id'), table_name='chat_history')
    op.drop_index(op.f('ix_chat_history_created_at'), table_name='chat_history')
    op.drop_index(op.f('ix_chat_history_content_id'), table_name='chat_history')
    op.drop_table('chat_history')
    # ### end Alembic commands ###
