# Shiksha Setu

**Safe, Open AI for Education & Noble Purposes**

A local-first, unrestricted AI platform that empowers learning, research, creativity, and noble causesâ€”while maintaining essential safety guardrails.

---

## Vision

Shiksha Setu is evolving beyond education into a **general-purpose AI** that:
- ğŸ“ **Educates** â€” STEM-aligned content, multilingual support, grade adaptation
- ğŸ”¬ **Researches** â€” Unrestricted knowledge exploration for academic work
- ğŸ¨ **Creates** â€” Assists with writing, coding, analysis, and creative tasks
- ğŸŒ **Serves Noble Purposes** â€” Healthcare, accessibility, social good

### Philosophy

> **Safe without being restricted. Powerful without being harmful.**

We block only genuinely dangerous content (weapons, malware, real harm) while trusting users with good intent for everything else.

---

## Overview

Shiksha Setu is a production-grade AI platform that runs entirely locally on Apple Silicon, with no cloud dependencies. It simplifies content, translates to Indian languages, answers questions, and generates audioâ€”all through a unified AI pipeline.

### Core Capabilities

| Feature | Description |
|---------|-------------|
| **Text Simplification** | Grade-level adaptation using Qwen2.5-3B-Instruct |
| **Translation** | 10 Indian languages via IndicTrans2-1B |
| **OCR** | Document extraction with GOT-OCR2.0 (95%+ accuracy on Indian scripts) |
| **Validation** | NCERT curriculum alignment using Gemma-2-2B-IT (â‰¥80% threshold) |
| **Text-to-Speech** | Dual TTS: Edge TTS (online) + MMS-TTS (offline, 1100+ languages) |
| **Speech-to-Text** | Whisper Large V3 Turbo (8x faster, 99 languages) |
| **RAG Q&A** | Intelligent question answering with BGE-M3 embeddings |
| **Reranking** | Improved retrieval with BGE-Reranker-v2-M3 |
| **Universal File Upload** | Process any file: images, PDFs, audio, video, spreadsheets |
| **A/B Testing** | Experiment framework for content optimization |
| **Multi-Tenancy** | Organization-level isolation and management |
| **Learning Recommendations** | Personalized content suggestions |
| **Question Generation** | Auto-generate quizzes from content |
| **Teacher Evaluation** | Content review and approval workflows |

### Universal File Processing

Upload **any file type** and get intelligent AI processing:

| File Type | Extensions | AI Processing |
|-----------|-----------|---------------|
| **Audio** | mp3, wav, m4a, ogg, flac, aac, wma | Whisper V3 transcription |
| **Video** | mp4, webm, mov, avi, mkv | Audio extraction + STT |
| **Documents** | pdf (multi-page), docx | GOT-OCR2 + Tesseract OCR |
| **Images** | png, jpg, jpeg, tiff, bmp, webp, gif, heic | GOT-OCR2 text extraction |
| **Spreadsheets** | csv, xls, xlsx | Direct parsing + analysis |
| **Text** | txt, md, json, xml, yaml | Direct content extraction |

### Supported Languages

Hindi â€¢ Tamil â€¢ Telugu â€¢ Bengali â€¢ Marathi â€¢ Gujarati â€¢ Kannada â€¢ Malayalam â€¢ Punjabi â€¢ Odia

---

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Frontend (React + Vite)                     â”‚
â”‚              TypeScript â€¢ TailwindCSS â€¢ Shadcn/UI               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       Backend (FastAPI)                          â”‚
â”‚     REST API â€¢ JWT Auth â€¢ Rate Limiting â€¢ Multi-Tier Cache      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â–¼                        â–¼                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   PostgreSQL    â”‚    â”‚   Multi-Tier     â”‚    â”‚  Unified Pipeline â”‚
â”‚ pgvector + HNSW â”‚    â”‚     Cache        â”‚    â”‚   (Optimized)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚  L1: Memory      â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚  L2: Redis       â”‚              â”‚
                       â”‚  L3: SQLite      â”‚              â–¼
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                               â”‚   Device Router   â”‚
                                               â”‚  GPUâ”‚MPSâ”‚ANEâ”‚CPU  â”‚
                                               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                         â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â–¼                â–¼                  â–¼                  â–¼
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚     MLX      â”‚ â”‚   CoreML     â”‚ â”‚     MPS      â”‚ â”‚   vLLM/HF    â”‚
           â”‚  (Apple M4)  â”‚ â”‚ (ANE 38TOPS) â”‚ â”‚   (Metal)    â”‚ â”‚   (CUDA)     â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚                â”‚                â”‚                â”‚
                    â–¼                â–¼                â–¼                â–¼
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚                        ML Models                             â”‚
           â”‚  Qwen2.5-3B â€¢ IndicTrans2 â€¢ GOT-OCR â€¢ Gemma-2-2B â€¢ BGE-M3    â”‚
           â”‚  Whisper V3 Turbo â€¢ Edge TTS â€¢ MMS-TTS â€¢ BGE-Reranker        â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Tech Stack

| Layer | Technology |
|-------|------------|
| **Frontend** | React 18 â€¢ TypeScript 5 â€¢ Vite 5 â€¢ TailwindCSS â€¢ Shadcn/UI |
| **Backend** | FastAPI â€¢ SQLAlchemy 2.0 â€¢ Pydantic v2 â€¢ Celery |
| **Database** | PostgreSQL 17 â€¢ pgvector â€¢ HNSW indexes |
| **Cache** | Multi-Tier: L1 (LRU) â†’ L2 (Redis) â†’ L3 (SQLite) |
| **ML/AI** | PyTorch â€¢ MLX (Apple Silicon) â€¢ CoreML â€¢ Transformers â€¢ vLLM |
| **Inference** | DeviceRouter: MLX/CoreML/MPS/CUDA with auto-selection |
| **Resilience** | Circuit Breakers â€¢ Graceful Degradation |
| **Observability** | OpenTelemetry â€¢ Prometheus â€¢ Grafana â€¢ Sentry |
| **Infrastructure** | Docker â€¢ Kubernetes |

---

## Quick Start

### Prerequisites

- **Python 3.11** (recommended) â€” See [Python Version Note](#python-version-note) below
- Node.js 20+
- Redis 7+
- PostgreSQL 17+ (or Supabase)

### Setup

```bash
git clone https://github.com/KDhiraj152/Siksha-Setu.git
cd shiksha_setu
./setup.sh
```

The setup script:
- Creates Python virtual environment
- Installs backend dependencies
- Installs frontend dependencies
- Generates secure JWT secret
- Initializes database schema
- Creates required directories

### Run

```bash
./start.sh
```

Starts:
- Backend API (port 8000)
- AI Pipeline (8 models ready)
- Frontend (port 3000)

Access: http://localhost:3000

### Stop

```bash
./stop.sh
```

---

## Python Version Note

**Why Python 3.11?**

This project requires **Python 3.11** specifically (not newer versions) for optimal ML/AI stack compatibility:

| Reason | Explanation |
|--------|-------------|
| **Pre-built Wheels** | All ML packages (PyTorch, MLX, Transformers, etc.) have pre-built wheels for 3.11, avoiding compilation |
| **Proven Stability** | Python 3.11 is mature and thoroughly tested with production ML frameworks |
| **Package Support** | Some packages don't yet support Python 3.13+ (e.g., verovio requires compilation on 3.14) |
| **Performance** | Python 3.11 includes significant performance improvements (~25% faster than 3.10) |
| **Apple Silicon** | MLX and CoreML tools are optimized and tested for Python 3.11 |

**Tested Package Versions (Python 3.11):**
- PyTorch 2.9.1, Transformers 4.57.3, MLX 0.30.0
- Sentence-Transformers 3.4.1, FastAPI 0.123.2
- Edge-TTS 7.2.3, Verovio 5.6.0

**Installation (macOS):**
```bash
brew install python@3.11
```

---

## Access Points

| Service | URL |
|---------|-----|
| Frontend | http://localhost:3000 |
| Chat Interface | http://localhost:3000/chat |
| Settings | http://localhost:3000/settings |
| Backend API (V2) | http://localhost:8000/api/v2 |
| Health Check | http://localhost:8000/api/v2/health |
| Hardware Status | http://localhost:8000/api/v2/hardware/status |
| Models Status | http://localhost:8000/api/v2/models/status |
| API Documentation | http://localhost:8000/docs |
| Prometheus Metrics | http://localhost:8000/metrics |

### V2 API Quick Reference

```bash
# Guest chat (no auth required)
curl -X POST http://localhost:8000/api/v2/chat/guest \
  -H "Content-Type: application/json" \
  -d '{"message": "What is photosynthesis?", "language": "hi", "grade_level": 5}'

# Streaming chat with conversation history (v2.3.1+)
curl -X POST http://localhost:8000/api/v2/chat/stream \
  -H "Content-Type: application/json" \
  -d '{
    "message": "Can you explain more?",
    "history": [
      {"role": "user", "content": "What is AI?"},
      {"role": "assistant", "content": "AI stands for Artificial Intelligence..."}
    ]
  }'

# Content simplification
curl -X POST http://localhost:8000/api/v2/content/simplify \
  -H "Content-Type: application/json" \
  -d '{"text": "Complex text here", "target_grade": 5}'
```

---

## Scripts

### Start/Stop (v3.3)

```bash
# Start all services
./start.sh                    # Full start with Docker
./start.sh --skip-docker      # Skip Docker (use existing containers)
./start.sh --quick            # Quick start (minimal checks)
./start.sh --monitoring       # Include Prometheus + Grafana

# Stop all services
./stop.sh                     # Graceful stop (keeps Docker containers)
./stop.sh --all               # Stop everything including Docker
./stop.sh --force             # Force kill immediately
./stop.sh --status            # Show optimization metrics before stopping
```

### Validation & Testing

```bash
# Run tests
./bin/test                    # Full test suite
./bin/smoke-test              # Quick smoke tests

# Validate system
./bin/validate                # System validation
./bin/validate-production     # Production readiness check
```

---

## Project Structure

```
shiksha_setu/
â”œâ”€â”€ README.md                 # This file
â”œâ”€â”€ CHANGELOG.md              # Version history
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ requirements.dev.txt      # Development dependencies
â”œâ”€â”€ docker-compose.yml        # Docker orchestration
â”œâ”€â”€ setup.sh                  # Setup script
â”œâ”€â”€ start.sh                  # Start services (v3.3)
â”œâ”€â”€ stop.sh                   # Stop services (v3.3)
â”‚
â”œâ”€â”€ bin/                      # Executable scripts
â”‚   â”œâ”€â”€ start                 # Start services
â”‚   â”œâ”€â”€ stop                  # Stop services
â”‚   â”œâ”€â”€ test                  # Run tests
â”‚   â”œâ”€â”€ validate              # System validation
â”‚   â””â”€â”€ smoke-test            # Quick smoke tests
â”‚
â”œâ”€â”€ backend/                  # FastAPI application (v4.1.0)
â”‚   â”œâ”€â”€ api/                  # Routes & endpoints
â”‚   â”‚   â”œâ”€â”€ main.py           # Application entry (V2 only)
â”‚   â”‚   â””â”€â”€ routes/
â”‚   â”‚       â”œâ”€â”€ v2_api.py     # Consolidated V2 API (all endpoints)
â”‚   â”‚       â”œâ”€â”€ health.py     # Health checks
â”‚   â”‚       â””â”€â”€ helpers.py    # Route utilities
â”‚   â”œâ”€â”€ core/                 # Core modules
â”‚   â”‚   â”œâ”€â”€ config.py         # Settings
â”‚   â”‚   â”œâ”€â”€ hardware_optimizer.py  # Apple Silicon detection
â”‚   â”‚   â”œâ”€â”€ ane_inference.py  # Neural Engine integration
â”‚   â”‚   â””â”€â”€ optimized/        # M4 5-Phase Optimizations
â”‚   â”‚       â”œâ”€â”€ device_router.py    # GPU/MPS/ANE routing
â”‚   â”‚       â”œâ”€â”€ async_optimizer.py  # Phase 1: Async-first
â”‚   â”‚       â”œâ”€â”€ gpu_pipeline.py     # Phase 3: GPU queue pipelining
â”‚   â”‚       â”œâ”€â”€ core_affinity.py    # Phase 4: P/E core routing
â”‚   â”‚       â””â”€â”€ memory_pool.py      # Phase 5: Buffer pools
â”‚   â”œâ”€â”€ cache/unified/        # Multi-tier cache (L1/L2/L3)
â”‚   â”‚   â”œâ”€â”€ multi_tier_cache.py  # BloomFilter, AdaptiveTTL, LZ4
â”‚   â”‚   â””â”€â”€ fast_serializer.py   # Phase 2: msgpack serialization
â”‚   â”œâ”€â”€ services/             # Business logic
â”‚   â”‚   â”œâ”€â”€ pipeline/         # AI pipeline orchestration
â”‚   â”‚   â”œâ”€â”€ inference/        # ML backends (MLX/CoreML)
â”‚   â”‚   â”œâ”€â”€ ocr.py            # GOT-OCR2 service
â”‚   â”‚   â”œâ”€â”€ rag.py            # RAG Q&A system
â”‚   â”‚   â”œâ”€â”€ review_queue.py   # Teacher review system
â”‚   â”‚   â””â”€â”€ student_profile.py # Student profiles
â”‚   â”œâ”€â”€ models/               # SQLAlchemy models
â”‚   â””â”€â”€ tasks/                # Celery tasks
â”‚
â”œâ”€â”€ frontend/                 # React + TypeScript + Vite (v2.1.0)
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ pages/            # Auth, Chat, LandingPage, Settings
â”‚       â”œâ”€â”€ components/       # Chat, Landing, UI, System components
â”‚       â”œâ”€â”€ context/          # SystemStatusContext, ThemeContext
â”‚       â”œâ”€â”€ api/              # V2 API client + system status
â”‚       â””â”€â”€ store/            # Zustand state management
â”‚
â”œâ”€â”€ tests/                    # Test suite
â”œâ”€â”€ infrastructure/           # DevOps configs
â”œâ”€â”€ docs/                     # Documentation
â”‚   â”œâ”€â”€ BACKEND.md            # Backend architecture
â”‚   â”œâ”€â”€ FRONTEND.md           # Frontend architecture
â”‚   â””â”€â”€ ai_pipeline.md        # AI pipeline details
â”œâ”€â”€ alembic/                  # Database migrations
â””â”€â”€ data/                     # Data storage
    â”œâ”€â”€ audio/                # Generated audio files
    â”œâ”€â”€ captions/             # Caption files
    â”œâ”€â”€ models/               # ML model cache
    â””â”€â”€ uploads/              # User uploads
```

---

## Environment Configuration

Key variables in `.env`:

```bash
# Application
ENVIRONMENT=development
DEBUG=true

# Database
DATABASE_URL=postgresql://user:pass@localhost:5432/shiksha_setu

# Redis
REDIS_URL=redis://localhost:6379/0

# Security
JWT_SECRET_KEY=<auto-generated>

# ML Models (2025 Optimal Stack)
DEVICE=auto                    # auto | cuda | mps | cpu
USE_QUANTIZATION=true

# Model IDs
SIMPLIFICATION_MODEL_ID=Qwen/Qwen2.5-3B-Instruct
TRANSLATION_MODEL_ID=ai4bharat/indictrans2-en-indic-1B
VALIDATION_MODEL_ID=google/gemma-2-2b-it
EMBEDDING_MODEL_ID=BAAI/bge-m3
RERANKER_MODEL_ID=BAAI/bge-reranker-v2-m3
TTS_MODEL_ID=facebook/mms-tts-hin
WHISPER_MODEL_ID=openai/whisper-large-v3-turbo

# TTS Configuration
EDGE_TTS_ENABLED=true          # Use Edge TTS as primary (online)
MMS_TTS_FALLBACK=true          # Use MMS-TTS as fallback (offline)
```

See `.env.example` for complete configuration.

---

## API Overview

### V2 API (Current - Recommended)

All endpoints are consolidated under `/api/v2/` with full hardware optimization.

#### Authentication
- `POST /api/v2/auth/register` â€” Create account
- `POST /api/v2/auth/login` â€” Get tokens
- `POST /api/v2/auth/refresh` â€” Refresh access token
- `GET /api/v2/auth/me` â€” Get current user

#### Chat
- `POST /api/v2/chat` â€” Authenticated chat
- `POST /api/v2/chat/stream` â€” Streaming chat (SSE)
- `POST /api/v2/chat/guest` â€” Guest chat (no auth)
- `GET /api/v2/chat/conversations` â€” List conversations
- `POST /api/v2/chat/conversations` â€” Create conversation
- `GET /api/v2/chat/conversations/{id}` â€” Get conversation
- `GET /api/v2/chat/conversations/{id}/messages` â€” Get messages
- `DELETE /api/v2/chat/conversations/{id}` â€” Delete conversation

#### Content Processing
- `POST /api/v2/content/process` â€” Full pipeline (simplify + translate + validate + TTS)
- `POST /api/v2/content/process/stream` â€” Full pipeline with streaming progress
- `POST /api/v2/content/simplify` â€” Simplify text (Qwen2.5-3B)
- `POST /api/v2/content/translate` â€” Translate (IndicTrans2)
- `POST /api/v2/content/tts` â€” Text-to-Speech (MMS-TTS/Edge TTS)
- `GET /api/v2/content/tts/voices` â€” List TTS voices

#### Speech-to-Text (Whisper V3 Turbo)
- `POST /api/v2/stt/transcribe` â€” Transcribe audio
- `GET /api/v2/stt/languages` â€” List supported languages

#### OCR (GOT-OCR2)
- `POST /api/v2/ocr/extract` â€” Extract text from images
- `GET /api/v2/ocr/capabilities` â€” Get OCR capabilities

#### Embeddings & Reranking (BGE-M3)
- `POST /api/v2/embeddings/generate` â€” Generate embeddings
- `POST /api/v2/embeddings/rerank` â€” Rerank documents

#### Q&A (RAG)
- `POST /api/v2/qa/process` â€” Process document for Q&A
- `POST /api/v2/qa/ask` â€” Ask questions

#### Progress & Quizzes
- `GET /api/v2/progress/stats` â€” User progress
- `POST /api/v2/progress/quiz/generate` â€” Generate quiz
- `POST /api/v2/progress/quiz/submit` â€” Submit answers

#### Embeddings
- `POST /api/v2/embeddings/generate` â€” Generate embeddings (BGE-M3)
- `POST /api/v2/embeddings/rerank` â€” Rerank documents (BGE-Reranker-v2-M3)
- `POST /api/v2/embed` â€” Generate embeddings (alternative)

#### Teacher Review
- `GET /api/v2/review/pending` â€” Get pending reviews
- `GET /api/v2/review/{response_id}` â€” Get flagged response
- `POST /api/v2/review/{response_id}/submit` â€” Submit review
- `GET /api/v2/review/stats` â€” Review statistics

#### Student Profile
- `GET /api/v2/profile/me` â€” Get student profile
- `PUT /api/v2/profile/me` â€” Update profile

#### AI Core
- `POST /api/v2/ai/explain` â€” Explain content
- `GET /api/v2/ai/prompts` â€” List prompts
- `POST /api/v2/ai/safety/check` â€” Safety check

#### Admin
- `POST /api/v2/admin/backup` â€” Create backup
- `GET /api/v2/admin/backups` â€” List backups

#### System
- `GET /api/v2/health` â€” Health check with device info
- `GET /api/v2/health/detailed` â€” Detailed health check
- `GET /api/v2/stats` â€” API statistics
- `GET /health` â€” Basic health check
- `GET /metrics` â€” Prometheus metrics

---

## Testing

```bash
# Activate environment
source venv/bin/activate

# All tests
pytest tests/

# With coverage
pytest tests/ --cov=backend --cov-report=html

# Frontend tests
cd frontend && npm test
```

---

## Troubleshooting

| Issue | Solution |
|-------|----------|
| Redis connection failed | Start Redis: `redis-server` |
| Database connection error | Check `DATABASE_URL` in `.env` |
| Model loading slow | First run downloads models (~10GB) |
| CUDA out of memory | Set `USE_QUANTIZATION=true` |
| Port already in use | Run `./stop.sh` first |

---

## License

MIT License â€” see [LICENSE](LICENSE)

---

â¸»

Created by: **K Dhiraj**
Email: k.dhiraj.srihari@gmail.com


